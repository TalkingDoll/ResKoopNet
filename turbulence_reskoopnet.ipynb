{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import scipy.io as sio\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of DATA:  (798, 295122)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('pressure_data.mat', 'r') as file:\n",
    "    # Load DATA_U and transpose it\n",
    "    DATA = np.array(file['/DATA']).T  # Transpose the data\n",
    "print(\"size of DATA: \", DATA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of DATA reduced:  (798, 150)\n",
      "size of X:  (797, 150)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Load the MAT file\n",
    "\n",
    "# Define the number of singular values/components to keep\n",
    "k = 150  # for example, keep 150 components\n",
    "\n",
    "# Perform SVD and keep only the first k of U, S, and VT\n",
    "U_reduced, S_reduced, VT_reduced = svd(DATA, full_matrices=False)\n",
    "U_reduced = U_reduced[:, :k]\n",
    "S_reduced = S_reduced[:k]\n",
    "VT_reduced = VT_reduced[:k, :]\n",
    "\n",
    "# Reconstruct the reduced data matrix\n",
    "DATA_reduced = np.dot(U_reduced, np.diag(S_reduced))\n",
    "\n",
    "# Now you can slice the DATA as before\n",
    "X = DATA_reduced[:-1]  # All rows except the last\n",
    "Y = DATA_reduced[1:]   # All rows except the first\n",
    "\n",
    "print(\"size of DATA reduced: \", DATA_reduced.shape)\n",
    "print(\"size of X: \", X.shape)\n",
    "# Clean up\n",
    "# del temp\n",
    "\n",
    "len_all = X.shape[0]\n",
    "data_x_train = X[:int(0.7*len_all),:]\n",
    "data_x_valid = X[int(0.7*len_all)+1:,:]\n",
    "\n",
    "data_y_train = Y[:int(0.7*len_all),:]\n",
    "data_y_valid = Y[int(0.7*len_all)+1:,:]\n",
    "\n",
    "data_train = [data_x_train, data_y_train]\n",
    "data_valid = [data_x_valid, data_y_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Epoch 1/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 205.6075 - val_loss: 58590.3094\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.2966\n",
      "Outer Epoch 2/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 205.6075 - val_loss: 58590.3173\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 205.6075 - val_loss: 58590.3415\n",
      "Outer Epoch 3/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6075 - val_loss: 58590.3427\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 205.6075 - val_loss: 58590.3204\n",
      "Outer Epoch 4/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.3046\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.2999\n",
      "Outer Epoch 5/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 205.6075 - val_loss: 58590.3024\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 205.6075 - val_loss: 58590.3107\n",
      "Outer Epoch 6/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.3131\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 205.6075 - val_loss: 58590.3074\n",
      "Outer Epoch 7/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6075 - val_loss: 58590.3093\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.3222\n",
      "Outer Epoch 8/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.3325\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 205.6075 - val_loss: 58590.3262\n",
      "Outer Epoch 9/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6075 - val_loss: 58590.3091\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 205.6075 - val_loss: 58590.2983\n",
      "Outer Epoch 10/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 205.6075 - val_loss: 58590.3058\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 205.6075 - val_loss: 58590.3204\n",
      "Outer Epoch 11/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 205.6075 - val_loss: 58590.3215\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3151\n",
      "Outer Epoch 12/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.3103\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 205.6075 - val_loss: 58590.3106\n",
      "Outer Epoch 13/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.3139\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3087\n",
      "Outer Epoch 14/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 205.6075 - val_loss: 58590.3019\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.3106\n",
      "Outer Epoch 15/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 205.6075 - val_loss: 58590.3190\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 205.6075 - val_loss: 58590.3171\n",
      "Outer Epoch 16/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 205.6075 - val_loss: 58590.3107\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3031\n",
      "Outer Epoch 17/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 205.6075 - val_loss: 58590.2966\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.2973\n",
      "Outer Epoch 18/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 205.6075 - val_loss: 58590.3022\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3023\n",
      "Outer Epoch 19/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 205.6075 - val_loss: 58590.3038\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 205.6075 - val_loss: 58590.3038\n",
      "Outer Epoch 20/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 205.6075 - val_loss: 58590.3057\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3116\n",
      "Outer Epoch 21/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 205.6075 - val_loss: 58590.3145\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6074 - val_loss: 58590.3154\n",
      "Outer Epoch 22/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 205.6074 - val_loss: 58590.3209\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 205.6074 - val_loss: 58590.3319\n",
      "Outer Epoch 23/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 205.6075 - val_loss: 58590.3298\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 205.6075 - val_loss: 58590.3158\n",
      "Outer Epoch 24/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 205.6075 - val_loss: 58590.3035\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 205.6075 - val_loss: 58590.3045\n",
      "Outer Epoch 25/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 205.6075 - val_loss: 58590.3115\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 205.6075 - val_loss: 58590.3104\n",
      "Outer Epoch 26/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 205.6075 - val_loss: 58590.3116\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 205.6075 - val_loss: 58590.3184\n",
      "Outer Epoch 27/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 205.6075 - val_loss: 58590.3302\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 205.6075 - val_loss: 58590.3322\n",
      "Outer Epoch 28/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 205.6075 - val_loss: 58590.3217\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 205.6075 - val_loss: 58590.3062\n",
      "Outer Epoch 29/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 205.6075 - val_loss: 58590.2968\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3067\n",
      "Outer Epoch 30/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 205.6075 - val_loss: 58590.3173\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3118\n",
      "Outer Epoch 31/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 205.6075 - val_loss: 58590.3073\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 205.6075 - val_loss: 58590.3116\n",
      "Error increased. Decay learning rate\n",
      "Outer Epoch 32/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 205.6075 - val_loss: 58590.3151\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 205.6075 - val_loss: 58590.3178\n",
      "Outer Epoch 33/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 205.6075 - val_loss: 58590.3170\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 205.6075 - val_loss: 58590.3121\n",
      "Outer Epoch 34/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 205.6075 - val_loss: 58590.3068\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 205.6075 - val_loss: 58590.3087\n",
      "Outer Epoch 35/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 205.6075 - val_loss: 58590.3153\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.3182\n",
      "Outer Epoch 36/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.3191\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3221\n",
      "Outer Epoch 37/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 205.6075 - val_loss: 58590.3227\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 205.6075 - val_loss: 58590.3216\n",
      "Outer Epoch 38/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 205.6074 - val_loss: 58590.3146\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 205.6075 - val_loss: 58590.3078\n",
      "Outer Epoch 39/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 205.6075 - val_loss: 58590.3063\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 205.6075 - val_loss: 58590.3091\n",
      "Outer Epoch 40/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 205.6075 - val_loss: 58590.3159\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 205.6075 - val_loss: 58590.3214\n",
      "Outer Epoch 41/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 205.6075 - val_loss: 58590.3281\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 205.6075 - val_loss: 58590.3331\n",
      "Outer Epoch 42/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 205.6075 - val_loss: 58590.3336\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 205.6075 - val_loss: 58590.3275\n",
      "Outer Epoch 43/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 205.6075 - val_loss: 58590.3159\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3071\n",
      "Outer Epoch 44/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 205.6075 - val_loss: 58590.3037\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.3097\n",
      "Outer Epoch 45/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 205.6075 - val_loss: 58590.3193\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.3261\n",
      "Outer Epoch 46/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 205.6075 - val_loss: 58590.3285\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3261\n",
      "Outer Epoch 47/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 205.6075 - val_loss: 58590.3263\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.3316\n",
      "Outer Epoch 48/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 205.6075 - val_loss: 58590.3360\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3357\n",
      "Outer Epoch 49/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6075 - val_loss: 58590.3220\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3013\n",
      "Outer Epoch 50/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.2891\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 205.6075 - val_loss: 58590.2867\n",
      "Outer Epoch 51/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6075 - val_loss: 58590.2984\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 205.6075 - val_loss: 58590.3186\n",
      "Error increased. Decay learning rate\n",
      "Outer Epoch 52/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 205.6075 - val_loss: 58590.3335\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.3403\n",
      "Outer Epoch 53/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.3360\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 205.6075 - val_loss: 58590.3246\n",
      "Outer Epoch 54/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 205.6075 - val_loss: 58590.3152\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 205.6075 - val_loss: 58590.3150\n",
      "Outer Epoch 55/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 205.6075 - val_loss: 58590.3165\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 205.6075 - val_loss: 58590.3123\n",
      "Outer Epoch 56/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.3090\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3020\n",
      "Outer Epoch 57/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.2902\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.2819\n",
      "Outer Epoch 58/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.2848\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.2941\n",
      "Outer Epoch 59/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 205.6075 - val_loss: 58590.3028\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 205.6075 - val_loss: 58590.3134\n",
      "Outer Epoch 60/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 205.6075 - val_loss: 58590.3190\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3145\n",
      "Outer Epoch 61/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.3008\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.2878\n",
      "Outer Epoch 62/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 205.6075 - val_loss: 58590.2854\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 205.6075 - val_loss: 58590.2933\n",
      "Outer Epoch 63/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.3054\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3112\n",
      "Outer Epoch 64/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 205.6075 - val_loss: 58590.3128\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 205.6075 - val_loss: 58590.3143\n",
      "Outer Epoch 65/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 205.6075 - val_loss: 58590.3136\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.3116\n",
      "Outer Epoch 66/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.3036\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.2964\n",
      "Outer Epoch 67/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.2959\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 205.6075 - val_loss: 58590.3003\n",
      "Outer Epoch 68/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.3065\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3132\n",
      "Outer Epoch 69/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 205.6075 - val_loss: 58590.3178\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6074 - val_loss: 58590.3212\n",
      "Outer Epoch 70/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 205.6075 - val_loss: 58590.3221\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.3216\n",
      "Outer Epoch 71/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 205.6075 - val_loss: 58590.3232\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6074 - val_loss: 58590.3247\n",
      "Outer Epoch 72/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 205.6074 - val_loss: 58590.3296\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3330\n",
      "Outer Epoch 73/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6075 - val_loss: 58590.3297\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.3258\n",
      "Outer Epoch 74/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 205.6075 - val_loss: 58590.3231\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6074 - val_loss: 58590.3204\n",
      "Outer Epoch 75/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6074 - val_loss: 58590.3179\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 205.6074 - val_loss: 58590.3161\n",
      "Outer Epoch 76/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 205.6074 - val_loss: 58590.3138\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 205.6074 - val_loss: 58590.3182\n",
      "Outer Epoch 77/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 205.6074 - val_loss: 58590.3261\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3243\n",
      "Outer Epoch 78/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6074 - val_loss: 58590.3163\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6074 - val_loss: 58590.3051\n",
      "Outer Epoch 79/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 205.6075 - val_loss: 58590.2983\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.2997\n",
      "Outer Epoch 80/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.3052\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3101\n",
      "Outer Epoch 81/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 205.6075 - val_loss: 58590.3127\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 205.6075 - val_loss: 58590.3171\n",
      "Error increased. Decay learning rate\n",
      "Outer Epoch 82/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6074 - val_loss: 58590.3248\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 205.6075 - val_loss: 58590.3355\n",
      "Outer Epoch 83/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 205.6075 - val_loss: 58590.3343\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 205.6075 - val_loss: 58590.3240\n",
      "Outer Epoch 84/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.3207\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.3244\n",
      "Outer Epoch 85/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 205.6075 - val_loss: 58590.3260\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 205.6075 - val_loss: 58590.3171\n",
      "Outer Epoch 86/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 205.6075 - val_loss: 58590.3036\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.2921\n",
      "Outer Epoch 87/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.2828\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.2855\n",
      "Outer Epoch 88/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6075 - val_loss: 58590.2955\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 205.6075 - val_loss: 58590.3038\n",
      "Outer Epoch 89/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 205.6075 - val_loss: 58590.3105\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 205.6075 - val_loss: 58590.3163\n",
      "Outer Epoch 90/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 205.6075 - val_loss: 58590.3214\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3175\n",
      "Outer Epoch 91/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.3123\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 205.6075 - val_loss: 58590.3144\n",
      "Error increased. Decay learning rate\n",
      "Outer Epoch 92/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 205.6075 - val_loss: 58590.3178\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3221\n",
      "Outer Epoch 93/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 205.6075 - val_loss: 58590.3273\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 205.6075 - val_loss: 58590.3299\n",
      "Outer Epoch 94/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 205.6075 - val_loss: 58590.3309\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.3318\n",
      "Outer Epoch 95/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 205.6075 - val_loss: 58590.3317\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 205.6075 - val_loss: 58590.3292\n",
      "Outer Epoch 96/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 205.6075 - val_loss: 58590.3273\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6075 - val_loss: 58590.3245\n",
      "Outer Epoch 97/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 205.6074 - val_loss: 58590.3173\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 205.6075 - val_loss: 58590.3103\n",
      "Outer Epoch 98/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 205.6075 - val_loss: 58590.3100\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 205.6075 - val_loss: 58590.3108\n",
      "Outer Epoch 99/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 205.6075 - val_loss: 58590.3121\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 205.6074 - val_loss: 58590.3144\n",
      "Outer Epoch 100/100\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 205.6074 - val_loss: 58590.3150\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 205.6074 - val_loss: 58590.3095\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from solver_resdmd_tf import KoopmanNN, KoopmanSolver\n",
    "\n",
    "# basis_function = PsiNN(layer_sizes=[100,100,100], n_psi_train=n_psi_train)\n",
    "# N_dict = n_psi_train + 3\n",
    "# # Dynamically import the solver module based on solver_index\n",
    "# filename = f'solver_{solver_index}_outputs_{N_dict}basis.mat'\n",
    "# solver_module = __import__(f\"solver_{solver_index}\", fromlist=['KoopmanDLSolver'])\n",
    "# KoopmanDLSolver = getattr(solver_module, 'KoopmanDLSolver')\n",
    "n_psi=99\n",
    "basis_function = KoopmanNN(layer_sizes=[120,120,120], n_psi_train=n_psi)\n",
    "\n",
    "# Using the dynamically imported solver\n",
    "solver = KoopmanSolver(dic=basis_function, \n",
    "                            target_dim=np.shape(data_train)[-1], \n",
    "                            reg=0.1)\n",
    "solver.build(data_train=data_train, \n",
    "                data_valid=data_valid, \n",
    "                epochs=100, \n",
    "                batch_size=500, \n",
    "                lr=1e-4, \n",
    "                log_interval=10, \n",
    "                lr_decay_factor=.8)\n",
    "\n",
    "# Results from solver\n",
    "evalues = solver.eigenvalues\n",
    "efuns_X = solver.eigenfunctions(X)\n",
    "efuns_Y = solver.eigenfunctions(Y)\n",
    "N_dict = np.shape(evalues)[0]    \n",
    "Psi_X = solver.get_Psi_X().numpy()\n",
    "Psi_Y = solver.get_Psi_Y().numpy()\n",
    "# Koopman_matrix_K = solver.K.numpy()\n",
    "# kpm_modes = solver.compute_mode()\n",
    "kpm_modes = np.dot(VT_reduced.T, solver.compute_mode())\n",
    "\n",
    "# Prepare data to save\n",
    "outputs = {\n",
    "    'evalues': evalues,\n",
    "    'efuns_X': efuns_X,\n",
    "    'efuns_Y': efuns_Y,\n",
    "    'N_dict': N_dict,\n",
    "    'Psi_X': Psi_X,\n",
    "    'Psi_Y': Psi_Y,\n",
    "    # 'K': Koopman_matrix_K,\n",
    "    'kpm_modes': kpm_modes,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797, 250)\n",
      "(797, 250)\n"
     ]
    }
   ],
   "source": [
    "print(efuns_X.shape)\n",
    "print(efuns_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs for n_psi_train=99 to data/turbulence_data\\turbulence_resdmd_250basis.mat\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'data/turbulence_data'  # Adjust the path as needed if you want a different location\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "# Save the outputs to a .mat file named according to the number of basis functions, inside the \"data\" folder\n",
    "file_path = os.path.join(folder_path, f'turbulence_resdmd_{N_dict}basis.mat')\n",
    "sio.savemat(file_path, outputs)\n",
    "print(f'Saved outputs for n_psi_train={n_psi} to {file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenvtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
